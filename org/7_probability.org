#+TITLE: Probability
#+AUTHOR: MARCUS BIRKENKRAHE
#+SUBTITLE: Applied math for data science (DSC 482/MTH 445) Fall 2022
#+PROPERTY: header-args:R :session *R* :results output :exports both
#+STARTUP: overview hideblocks indent inlineimages entitiespretty
:REVEAL_PROPERTIES:
#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js
#+REVEAL_REVEAL_JS_VERSION: 4
#+REVEAL_THEME: black
#+REVEAL_INIT_OPTIONS: transition: 'cube'
:END:
* What's in this lecture?
#+attr_html: :width 300px
#+caption: Did the Sun just explode? (It's night, so we're not sure) by xkcd
[[../img/7_xkcd.png]]

Source: [[https://www.explainxkcd.com/wiki/index.php/1132:_Frequentists_vs._Bayesians][xkcd cartoon 1132: Frequentists vs. Bayesians]]

- Frequentist vs. Bayesian Probability
- Intersection, Union and Complement
- Monte Carlo Simulations
- Simulating a deck of playing cars
- The ~gtools~ R combinatorics and utilities package
- ~sample~, ~replicate~, ~expand.grid~, ~combn~, ~combinations~, ~permutations~

* What is a 'probability'?
[[../img/7_probability_and_statistics.png]]

- A number that describes the magnitude of chance associated with
  making a particular observation or statement.

- Probability is always a continuous number p \in [0,1].

- This abstract-mathematical notion becomes tangible only in context
  with an (observable) event that can be predicted

- Probability theory predicts event data based on models - e.g. "each
  /outcome/ on a fair die has a probability of 1/6 in any given roll"

- Statistics predicts models given event data, e.g. "the /average/ of a
  series of ~n~ observations is the sum of their values over ~n~."

* Events and probability

- An event A refers to a specific outcome that can occur.

- The chance that A occurs is denoted as ~Pr(A)~. ~Pr(A) = 1~ means that
  an event will occur with absolute certainty, ~Pr(A) = 0~ means that it
  cannot occur ever.

- ~Pr(A)~ is known as a /frequentist/ or /classical/ probability. It is the
  relative frequency with which an event occurs over many identical,
  objective trials.

- /Chance/ computations are /always/ models that live and die on their
  assumptions, i.e. reality is modeled as an abstraction.

- Remember: real life is not an abstraction but a mess of details:
  #+attr_html: :width 600px
  [[../img/7_probability.png]]
  [[https://www.explainxkcd.com/wiki/index.php/881:_Probability][Source: xkcd explained - cancer comics]][fn:2]

* Example 1: fair die
#+attr_html: :width 400px
[[../img/7_fairdie.png]]

- Example: the six-sided, "fair" die, which does not exist, has
  ~Pr(A) = 1/6~ for every one of its outcomes ~A \in {1,2,3,4,5,6}~. The
  die roll is assumed to be /identical/ and /objective/, though it never
  really is.

- The (empirical) law of large numbers "guarantees" that a large
  enough number of observations will yield the ideal ~Pr(A)~.

- We can *simulate* this using R:
  1) define a standard, six-sided, fair die
  2) roll die once (with replacement)
  #+begin_src R
    die <- rep(x=1:6)  # define a standard die
    die_hard <- letters[1:3]
    sample(
      x = die_hard, # vector to sample from
      size = 1)  # size of sample - "roll die once"
  #+end_src

  #+RESULTS:
  : [1] "b"

- ~sample~ takes a sample of the specified ~size~ from the elements of ~x~
  either with or without replacement (~replace~).

* Visualization - "Monte Carlo Simulation"

- We want to repeat the die roll an infinite number of times

- Instead we repeat the experiment a large enough number of times ~N~ to
  make the results /practically equivalent/ to repeating forever

- We use the ~replicate~ function (from the ~apply~ family)
  1) define number of repetitions ~N~
  2) define event vector ~event~
  3) print frequencies of each side with ~table~
  4) print proportions with ~prop.table~
  5) print sample average with ~mean~
  6) plot the distribution using ~barplot~ (show in separate window)
  #+name: roll_die
  #+begin_src R
    die <- rep(1:6)  # define standard die
    N <- 100                                   #1
    events <- replicate(N, sample(die,1))     #2
    table(events) -> tbl                      #3
    tbl
    prop.table(table(events)) -> proportions  #4
    proportions
    mean(proportions)                         #5
    barplot(height=proportions)
  #+end_src

  #+RESULTS: roll_die
  : events
  :  1  2  3  4  5  6 
  : 21 13 17 12 18 19
  : events
  :    1    2    3    4    5    6 
  : 0.21 0.13 0.17 0.12 0.18 0.19
  : [1] 0.1666667

- The law of large number is visible in the barplot:
  #+begin_src R :results graphics file :file ../img/dieroll.png :noweb yes
    <<roll_die>>
    barplot(height=proportions)
  #+end_src

  #+RESULTS:
  [[file:../img/dieroll.png]]

* Example 2: quantum particles
#+attr_html: :width 400px
[[../img/7_cat.png]]

- In quantum physics, particles no longer have a definite position but
  instead a (non-standard) probability distribution ("Heisenberg
  uncertainty principle"[fn:1])

- Quantum physics is also a model-based abstraction of the real
  world. Its applications (like the laser, nuclear power etc.) are
  still real.

- In particle physics experiments, measuring the outcome of big data
  events relies on probabilistic simulations like Monte Carlo, which
  are also common place in risk analysis and investment data science.

* Example 3: Bayesian marriage
#+attr_html: :width 400px
[[../img/7_marriage.jpg]]

- Say you're married and arrive home much later than usual (event A).

- Let B be the event "your partner is angry" because you're late.

- B cannot easily /objectively/ observed or computed.

- Instead, you might assign a value to Pr(B) based on experience: "I
  think Pr(B) = 0.5" because your experience tells you that your
  chances are 50-50.

- Instead of an impartial experiment, your chance computation is based
  on personal impression and knowledge of your spouse or mood, and it
  is not easily /reproducable/.

- This is known as /Bayesian/ probability, which uses prior knowledge or
  subjective belief to inform the computation (smaller samples needed)

- By contrast, we're looking at the /frequentist/ or classical
  interpretation of probability, which implies "objectivity"

#+attr_html: :width 300px
#+caption: Did the Sun just explode? (It's night, so we're not sure) by xkcd
[[../img/7_xkcd.png]]
Source: [[https://www.explainxkcd.com/wiki/index.php/1132:_Frequentists_vs._Bayesians][xkcd cartoon 1132: Frequentists vs. Bayesians]]

* Conditional probability

/Die example:/
#+begin_quote
Event A: "you roll a 4 or more" - Pr(A) = Pr({4,5,6}) = 3/6 = 1/2
Event B: "you roll an even number" - Pr(B) = Pr({2,4,6}) = 3/6 = 1/2
#+end_quote

- A /conditional/ probability is the probability of one event occurring
  after taking into account the occurrence of another event.

- ~Pr(A|B)~ is the probability that A occurs /given/ that B has occurred.
- If ~Pr(A|B) = Pr(A)~ then A and B are (stochastically) /independent/
- If ~Pr(A|B) \ne Pr(A)~ then A and B are (stochastically) /dependent/
- Generally, ~Pr(A|B) \ne Pr(B|A)~

/Die example:/
- If B has occurred already, an even number {2,4,6} has been rolled,
  and the chance to roll a 4 or more is ~Pr(A|B) = 2/3~ ({4} or {6} out
  of {2,4,6})

- Consequently, A and B are dependent: "the chance to roll a 4 or more
  is greater if an even number has already been rolled"[fn:3]

* Intersection
#+attr_html: :width 300px
[[../img/7_intersection.png]]

- The intersection of two events A and B, ~Pr(A \cap B)~ is the
  probability that both A and B occur "simultaneously"

- ~Pr(A \cap B) = Pr(A|B) \times Pr(B)~ or ~Pr(B|A) \times Pr(A)~

- ~Pr(A \cap B) = 0~ means A and B are /mutually exclusive/ and cannot occur
  simultaneously

- If A and B are independent, ~Pr(A|B) = Pr(A)~ or ~Pr(B|A) = Pr(B)~ and
  ~Pr(A \cap B) = Pr(A) \times Pr(B)~

- Die example: what's the probability that on a single toss you roll
  an even number (B) /and/ it's a 4 or more (A)?

- Since ~Pr(A|B) = 2/3~ and ~Pr(B) = 1/2~, ~Pr(A \cap B) = 2/3 \times 1/2 = 1/3~

- A and B are /not/ mutually exclusive since ~Pr(A \cap B) \ne 0~: it's
  possible to roll a number that's both even and at least 4.

- In R, the ~intersect~ function performs set intersection of two
  vectors:
  #+begin_src R
    (x <- c(sort(sample(1:20, 7)), NA))
    (y <- c(sort(sample(3:23, 6)), NA))
    intersect(x,y)
  #+end_src

  #+RESULTS:
  : [1]  2  3  4  6  8  9 14 NA
  : [1]  3  4 11 12 13 17 NA
  : [1]  3  4 NA

- Does ~intersect~ also work on strings?
  #+begin_src R
    DE <- c("Dr.", "Marcus", "Speh", "Birkenkrahe")
    US <- c("Dr.", "Alice", "Jewel", "Speh")
    intersect(DE,US)
  #+end_src

* Union
#+attr_html: :width 300px
[[../img/7_union.png]]

- ~Pr(A \cup B)~ is the probability that either A or B occurs.

- ~Pr(A \cup B) = Pr(A) + Pr(B) - Pr(A \cap B)~

- The intersection needs to be subtracted not to count it twice

- If A and B are mutually exclusive then ~Pr(A \cup B) = Pr(A) + Pr(B)~

- /Die example/: the probability that you observe an even number or one
  that is at least 4 is ~Pr(A \cup B) = 1/2 + 1/2 - 1/3 = 4/6 = 2/3~
  #+begin_src R
    all.equal(1/2+1/2-1/3, 2/3)
  #+end_src

- In R, the ~union~ function performs set union of two vectors:
  #+begin_src R
    (x <- c(sort(sample(1:20, 7)), NA))
    (y <- c(sort(sample(3:23, 6)), NA))
    union(x,y)
  #+end_src

  #+RESULTS:
  : [1]  1  6  7  8  9 12 14 NA
  : [1]  4  5 14 18 19 23 NA
  :  [1]  1  6  7  8  9 12 14 NA  4  5 18 19 23

* Complement
#+attr_html: :width 300px
[[../img/7_complement.png]]

- The complement of ~Pr(A)~ is the probability that A does not occur
  (usually written with an overline), or ~1 - Pr(A)~

- /Die example/: the probability that you do not roll a 4 or greater (A)
  is ~1 - 1/2 = 1/2~. If none of {4,5,6} is obtained, you must have
  rolled a {1,2,3}.

* IN PROGRESS Building and drawing from a deck of cards
** Creating and picking from an urn

- To compute the probability distribution of one draw of a simple set,
  like a set of six ~beads~ is simple even manually.

- Example: pick a bead at random from an urn with six ~beads~

- First create the urn:
  #+begin_src R
    beads <- rep(c("red","blue"), times = c(2,3))
    beads
  #+end_src

  #+RESULTS:
  : [1] "red"  "red"  "blue" "blue" "blue"

- Pick one bead at random (repeat execution a few times):
  #+begin_src R
    sample(beads,1)
  #+end_src

  #+RESULTS:
  : [1] "red"
  
** Repeated picking from an urn

- Repeat picking from an urn ~B~ times using ~replicate~:
  #+begin_src R :results silent
    B <- 10000
    events <- replicate(B, sample(beads, 1))
  #+end_src

- Print the distribution: what output do you expect?
  #+begin_src R
    tab <- table(events)
    tab
  #+end_src

  #+RESULTS:
  : events
  : blue  red 
  : 5892 4108

- Plot the proportions: what output do you expect?
  #+begin_src R
    prop <- prop.table(tab)
    prop
  #+end_src

  #+RESULTS:
  : events
  :   blue    red 
  : 0.5892 0.4108
  
- Plot the distribution: what output do you expect?
  #+begin_src R :results graphics file :file urn.png
    barplot(tab, col=c("blue","red"))
  #+end_src

  #+RESULTS:
  [[file:urn.png]]

- As ~B~ gets larger, the estimates will get closer to ~2/5=0.4~ for ~red~
  and ~3/5=0.6~ for ~blue~.

** Setting the random seed

- To ensure that results with pseudo-random numbers are identical

- A popular way to pick the seed: year-month-day, e.g.
  #+begin_src R
    2022-11-17
  #+end_src

  #+RESULTS:
  : [1] 1994

- Consequently:
  #+begin_src R
    set.seed(1994)
  #+end_src
  
** With and without replacement

- The ~sample~ function has an argument to pick more than one element
  from the urn (by default, ~replace=FALSE~, without replacement

- ~sample~ can be used directly without ~replicate~ to repeat the same
  experiment of picking 1 out of the 5 ~beads~, continually, under the
  same conditions, /with replacement/:
  #+begin_src R
    set.seed(1994)
    events <- sample(beads, B, replace=TRUE)
    prop.table(table(events))
  #+end_src

  #+RESULTS:
  : events
  :   blue    red 
  : 0.5966 0.4034
  
- Setting the seed leads to identical results every time

** IN PROGRESS Combinations and permutations

- For more complicated cases than six beads or dice, the computations
  are perhaps not simple: what is the probability that if I draw five
  cards from a deck of 52 playing cards, I get all cards of the same
  suit (a "flush" in poker)?

- To simulate this scenario, we build a deck of cards

*** TO BE CONTINUED

* References

- [[https://nostarch.com/bookofr][Davies TD (2016). Book of R. NoStarch Press. URL: nostarch.com]]

- Matloff N (2019). Probability and Statistics for Data Science. CRC
  Press.

- [[https://terrytao.files.wordpress.com/2012/12/gsm-126-tao5-measure-book.pdf][Tao T (2011). An introduction to measure theory. Am Math Soc.]]

* Footnotes

[fn:3]In this example, ~Pr(A|B) = Pr(B|A)~ - if A has occurred already,
one of {4,5,6} has been rolled, and the chance to roll an even number
is also ~Pr(B|A) = 2/3~ ({4} or {6} out of {4,5,6}).

[fn:2]Apparently, Randall Munroe's, the author of the xkcd cartoon's
fianceé had cancer and passed away a few days after this comic was
posted. Its subtitle is: "My normal approach is useless here, too".

[fn:1]One of these paradoxes is the [[https://en.wikipedia.org/wiki/Uncertainty_principle][Heisenberg uncertainty principle]]:
"We cannot know both the position and the speed of a particle, such as
a photon or electron, with perfect accuracy": \Delta x \Delta y \sim h
